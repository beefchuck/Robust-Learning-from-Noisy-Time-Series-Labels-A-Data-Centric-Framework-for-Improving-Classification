{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### INTEGRATED HAR BASELINE MODELS WITH TACL-NET ###\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "from collections import deque, Counter\n",
        "import warnings\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import urllib.request\n",
        "import zipfile\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# 0. HAR DATA LOADER (Enhanced from original)\n",
        "class UCIHARDataLoader:\n",
        "    \"\"\"Load and preprocess UCI Human Activity Recognition dataset with enhanced logging\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir=\"./HAR_data\", download=True):\n",
        "        self.data_dir = data_dir\n",
        "        self.dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\"\n",
        "        self.activities = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
        "\n",
        "        if download:\n",
        "            self.download_and_extract()\n",
        "\n",
        "    def download_and_extract(self):\n",
        "        \"\"\"Download and extract UCI HAR dataset\"\"\"\n",
        "        os.makedirs(self.data_dir, exist_ok=True)\n",
        "        zip_path = os.path.join(self.data_dir, \"UCI_HAR_Dataset.zip\")\n",
        "        extract_path = os.path.join(self.data_dir, \"UCI HAR Dataset\")\n",
        "\n",
        "        if not os.path.exists(extract_path):\n",
        "            if not os.path.exists(zip_path):\n",
        "                print(\"Downloading UCI HAR Dataset...\")\n",
        "                try:\n",
        "                    urllib.request.urlretrieve(self.dataset_url, zip_path)\n",
        "                    print(\"Downloaded UCI HAR Dataset\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to download: {e}\")\n",
        "                    print(\"Please download manually from: https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones\")\n",
        "                    return\n",
        "\n",
        "            print(\"Extracting dataset...\")\n",
        "            try:\n",
        "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(self.data_dir)\n",
        "                print(\"Dataset extracted successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to extract: {e}\")\n",
        "\n",
        "    def load_data_from_files(self, base_path):\n",
        "        \"\"\"Load data from UCI HAR dataset files\"\"\"\n",
        "        try:\n",
        "            # Try different possible directory structures\n",
        "            possible_paths = [\n",
        "                os.path.join(base_path, \"UCI HAR Dataset\"),\n",
        "                os.path.join(base_path, \"UCI_HAR_Dataset\"),\n",
        "                base_path\n",
        "            ]\n",
        "\n",
        "            dataset_path = None\n",
        "            for path in possible_paths:\n",
        "                train_path = os.path.join(path, \"train\")\n",
        "                test_path = os.path.join(path, \"test\")\n",
        "                if os.path.exists(train_path) and os.path.exists(test_path):\n",
        "                    dataset_path = path\n",
        "                    break\n",
        "\n",
        "            if dataset_path is None:\n",
        "                raise FileNotFoundError(\"Could not find UCI HAR dataset structure\")\n",
        "\n",
        "            print(f\"Loading data from: {dataset_path}\")\n",
        "\n",
        "            # Load training data\n",
        "            X_train = np.loadtxt(os.path.join(dataset_path, \"train\", \"X_train.txt\"))\n",
        "            y_train = np.loadtxt(os.path.join(dataset_path, \"train\", \"y_train.txt\"), dtype=int)\n",
        "            subject_train = np.loadtxt(os.path.join(dataset_path, \"train\", \"subject_train.txt\"), dtype=int)\n",
        "\n",
        "            # Load test data\n",
        "            X_test = np.loadtxt(os.path.join(dataset_path, \"test\", \"X_test.txt\"))\n",
        "            y_test = np.loadtxt(os.path.join(dataset_path, \"test\", \"y_test.txt\"), dtype=int)\n",
        "            subject_test = np.loadtxt(os.path.join(dataset_path, \"test\", \"subject_test.txt\"), dtype=int)\n",
        "\n",
        "            # Convert labels to 0-indexed\n",
        "            y_train = y_train - 1\n",
        "            y_test = y_test - 1\n",
        "\n",
        "            # Load feature names (optional)\n",
        "            try:\n",
        "                features_path = os.path.join(dataset_path, \"features.txt\")\n",
        "                if os.path.exists(features_path):\n",
        "                    self.feature_names = []\n",
        "                    with open(features_path, 'r') as f:\n",
        "                        for line in f:\n",
        "                            self.feature_names.append(line.strip().split()[1])\n",
        "                else:\n",
        "                    self.feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
        "            except:\n",
        "                self.feature_names = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
        "\n",
        "            print(f\"Data loaded successfully:\")\n",
        "            print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "            print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "            print(f\"Number of features: {X_train.shape[1]}\")\n",
        "            print(f\"Number of subjects: train={len(np.unique(subject_train))}, test={len(np.unique(subject_test))}\")\n",
        "            print(f\"Activities: {self.activities}\")\n",
        "            print(f\"Train class distribution: {np.bincount(y_train)}\")\n",
        "            print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
        "\n",
        "            return X_train, y_train, X_test, y_test, subject_train, subject_test\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading real UCI HAR data: {e}\")\n",
        "            print(\"Creating synthetic HAR-like data...\")\n",
        "            return self.create_synthetic_har_data()\n",
        "\n",
        "    def create_synthetic_har_data(self):\n",
        "        \"\"\"Create synthetic HAR-like data for testing\"\"\"\n",
        "        print(\"Generating synthetic HAR data...\")\n",
        "        np.random.seed(42)\n",
        "\n",
        "        n_features = 561\n",
        "        n_train = 7352\n",
        "        n_test = 2947\n",
        "        n_classes = 6\n",
        "\n",
        "        # Generate realistic sensor-like features\n",
        "        X_train = []\n",
        "        y_train = []\n",
        "        X_test = []\n",
        "        y_test = []\n",
        "\n",
        "        for class_idx in range(n_classes):\n",
        "            # Different activity patterns\n",
        "            if class_idx == 0:  # WALKING\n",
        "                base_freq = 2.0\n",
        "                movement_pattern = \"periodic\"\n",
        "            elif class_idx == 1:  # WALKING_UPSTAIRS\n",
        "                base_freq = 1.5\n",
        "                movement_pattern = \"upward\"\n",
        "            elif class_idx == 2:  # WALKING_DOWNSTAIRS\n",
        "                base_freq = 2.5\n",
        "                movement_pattern = \"downward\"\n",
        "            elif class_idx == 3:  # SITTING\n",
        "                base_freq = 0.1\n",
        "                movement_pattern = \"static\"\n",
        "            elif class_idx == 4:  # STANDING\n",
        "                base_freq = 0.2\n",
        "                movement_pattern = \"static\"\n",
        "            else:  # LAYING\n",
        "                base_freq = 0.05\n",
        "                movement_pattern = \"static\"\n",
        "\n",
        "            # Generate training samples\n",
        "            n_train_class = n_train // n_classes\n",
        "            for _ in range(n_train_class):\n",
        "                features = self.generate_har_features(n_features, base_freq, movement_pattern)\n",
        "                X_train.append(features)\n",
        "                y_train.append(class_idx)\n",
        "\n",
        "            # Generate test samples\n",
        "            n_test_class = n_test // n_classes\n",
        "            for _ in range(n_test_class):\n",
        "                features = self.generate_har_features(n_features, base_freq, movement_pattern)\n",
        "                X_test.append(features)\n",
        "                y_test.append(class_idx)\n",
        "\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "        X_test = np.array(X_test)\n",
        "        y_test = np.array(y_test)\n",
        "\n",
        "        # Create dummy subject arrays\n",
        "        subject_train = np.random.randint(1, 31, len(y_train))\n",
        "        subject_test = np.random.randint(1, 31, len(y_test))\n",
        "\n",
        "        print(f\"Generated synthetic HAR data:\")\n",
        "        print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "        print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "\n",
        "        return X_train, y_train, X_test, y_test, subject_train, subject_test\n",
        "\n",
        "    def generate_har_features(self, n_features, base_freq, movement_pattern):\n",
        "        \"\"\"Generate realistic HAR features based on activity type\"\"\"\n",
        "        features = []\n",
        "\n",
        "        for i in range(n_features):\n",
        "            if i < n_features // 3:  # Time domain features\n",
        "                if movement_pattern == \"static\":\n",
        "                    value = np.random.normal(0, 0.1)\n",
        "                elif movement_pattern == \"periodic\":\n",
        "                    value = np.sin(base_freq * np.random.uniform(0, 2*np.pi)) + np.random.normal(0, 0.2)\n",
        "                elif movement_pattern == \"upward\":\n",
        "                    value = abs(np.sin(base_freq * np.random.uniform(0, 2*np.pi))) + np.random.normal(0.2, 0.15)\n",
        "                else:  # downward\n",
        "                    value = -abs(np.sin(base_freq * np.random.uniform(0, 2*np.pi))) + np.random.normal(-0.2, 0.15)\n",
        "            elif i < 2 * n_features // 3:  # Frequency domain features\n",
        "                value = np.random.exponential(1/(base_freq + 0.1)) * np.random.choice([-1, 1])\n",
        "            else:  # Statistical features\n",
        "                value = np.random.normal(0, 1) * (base_freq if movement_pattern != \"static\" else 0.1)\n",
        "\n",
        "            features.append(value)\n",
        "\n",
        "        return np.array(features)\n",
        "\n",
        "    def load_data(self, custom_dir=None):\n",
        "        \"\"\"Main method to load HAR data\"\"\"\n",
        "        if custom_dir:\n",
        "            return self.load_data_from_files(custom_dir)\n",
        "        else:\n",
        "            return self.load_data_from_files(self.data_dir)\n",
        "\n",
        "\n",
        "# 1. SAM OPTIMIZER FROM TACL-NET\n",
        "class SAM(torch.optim.Optimizer):\n",
        "    \"\"\"Sharpness-Aware Minimization optimizer\"\"\"\n",
        "    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n",
        "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
        "\n",
        "        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n",
        "        super(SAM, self).__init__(params, defaults)\n",
        "\n",
        "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
        "        self.param_groups = self.base_optimizer.param_groups\n",
        "        self.defaults.update(self.base_optimizer.defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def first_step(self, zero_grad=False):\n",
        "        grad_norm = self._grad_norm()\n",
        "        for group in self.param_groups:\n",
        "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
        "\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None: continue\n",
        "                self.state[p][\"old_p\"] = p.data.clone()\n",
        "                e_w = (torch.pow(p, 2) if group[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n",
        "                p.add_(e_w)\n",
        "\n",
        "        if zero_grad: self.zero_grad()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def second_step(self, zero_grad=False):\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None: continue\n",
        "                p.data = self.state[p][\"old_p\"]\n",
        "\n",
        "        self.base_optimizer.step()\n",
        "        if zero_grad: self.zero_grad()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
        "        closure = torch.enable_grad()(closure)\n",
        "\n",
        "        self.first_step(zero_grad=True)\n",
        "        closure()\n",
        "        self.second_step()\n",
        "\n",
        "    def _grad_norm(self):\n",
        "        shared_device = self.param_groups[0][\"params\"][0].device\n",
        "        norm = torch.norm(\n",
        "                    torch.stack([\n",
        "                        ((torch.abs(p) if group[\"adaptive\"] else 1.0) * p.grad).norm(dtype=torch.float32).to(shared_device)\n",
        "                        for group in self.param_groups for p in group[\"params\"]\n",
        "                        if p.grad is not None\n",
        "                    ]),\n",
        "                    dtype=torch.float32\n",
        "               )\n",
        "        return norm\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        super().load_state_dict(state_dict)\n",
        "        self.base_optimizer.param_groups = self.param_groups\n",
        "\n",
        "\n",
        "# 2. TACL-NET COMPONENTS\n",
        "class BalancedNoiseRobustLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.8, temp=0.3):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.temp = temp\n",
        "        self.base_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, preds, targets, conf_scores=None):\n",
        "        probs = F.softmax(preds/self.temp, dim=1)\n",
        "        ce_loss = self.base_loss(preds, targets)\n",
        "        cons_loss = -torch.mean(torch.sum(probs * torch.log(probs + 1e-8), dim=1))\n",
        "        return self.alpha*ce_loss + (1-self.alpha)*cons_loss\n",
        "\n",
        "class EnhancedMLPEncoder(nn.Module):\n",
        "    \"\"\"MLP encoder optimized for HAR feature vectors\"\"\"\n",
        "    def __init__(self, input_dim=561, latent_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(256, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.feature_extractor(x)\n",
        "\n",
        "class ActivityAttention(nn.Module):\n",
        "    \"\"\"Attention mechanism for activity-specific feature selection\"\"\"\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(latent_dim, latent_dim // 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(latent_dim // 2, latent_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        att_weights = self.attention(x)\n",
        "        return x * att_weights\n",
        "\n",
        "\n",
        "# 3. MODEL DEFINITIONS\n",
        "class CNN1D_HAR_Enhanced(nn.Module):\n",
        "    \"\"\"Enhanced 1D CNN for HAR with temporal smoothing and confidence reweighting\"\"\"\n",
        "    def __init__(self, input_size, num_classes=6, num_channels=64):\n",
        "        super(CNN1D_HAR_Enhanced, self).__init__()\n",
        "\n",
        "        self.input_reshape = lambda x: x.unsqueeze(1)\n",
        "\n",
        "        # Adapted for HAR signals (561 features)\n",
        "        self.conv1 = nn.Conv1d(1, num_channels, kernel_size=9, padding=4)\n",
        "        self.bn1 = nn.BatchNorm1d(num_channels)\n",
        "        self.pool1 = nn.MaxPool1d(3, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(num_channels, num_channels*2, kernel_size=7, padding=3)\n",
        "        self.bn2 = nn.BatchNorm1d(num_channels*2)\n",
        "        self.pool2 = nn.MaxPool1d(3, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(num_channels*2, num_channels*4, kernel_size=5, padding=2)\n",
        "        self.bn3 = nn.BatchNorm1d(num_channels*4)\n",
        "        self.pool3 = nn.MaxPool1d(3, stride=2)\n",
        "\n",
        "        conv_output_size = self._get_conv_output_size(input_size)\n",
        "\n",
        "        self.fc1 = nn.Linear(conv_output_size, 256)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def _get_conv_output_size(self, input_size):\n",
        "        x = torch.zeros(1, 1, input_size)\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.pool3(F.relu(self.conv3(x)))\n",
        "        return x.numel()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_reshape(x)\n",
        "\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        logits = self.fc3(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "class BiLSTM_HAR_Enhanced(nn.Module):\n",
        "    \"\"\"Enhanced Bi-LSTM for HAR with attention mechanism\"\"\"\n",
        "    def __init__(self, input_size, hidden_size=128, num_layers=2, num_classes=6):\n",
        "        super(BiLSTM_HAR_Enhanced, self).__init__()\n",
        "\n",
        "        self.input_size = input_size  # 561 for HAR\n",
        "\n",
        "        # Reshape 561 features into smaller chunks for sequential processing\n",
        "        self.seq_len = 33  # 561 / 17 = 33, so 17 features per time step\n",
        "        self.feature_per_step = 17\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.feature_per_step,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=0.3 if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Attention mechanism\n",
        "        lstm_output_size = hidden_size * 2\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, 561)\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Reshape to (batch_size, seq_len, feature_per_step)\n",
        "        # Take only first 561 features if needed, pad if less\n",
        "        if x.shape[1] > 561:\n",
        "            x = x[:, :561]\n",
        "        elif x.shape[1] < 561:\n",
        "            padding = torch.zeros(batch_size, 561 - x.shape[1], device=x.device)\n",
        "            x = torch.cat([x, padding], dim=1)\n",
        "\n",
        "        # Reshape: 561 -> (33, 17)\n",
        "        x = x.view(batch_size, self.seq_len, self.feature_per_step)\n",
        "\n",
        "        # LSTM forward pass\n",
        "        lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, hidden_size*2)\n",
        "\n",
        "        # Attention-based aggregation\n",
        "        attention_weights = self.attention(lstm_out)  # (batch_size, seq_len, 1)\n",
        "        attention_weights = F.softmax(attention_weights.squeeze(-1), dim=1)  # (batch_size, seq_len)\n",
        "\n",
        "        # Weighted average\n",
        "        attended_output = torch.sum(lstm_out * attention_weights.unsqueeze(-1), dim=1)\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(attended_output)\n",
        "\n",
        "        return logits\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 1:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(0)\n",
        "        x = x + self.pe[:seq_len, :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerHAR_Enhanced(nn.Module):\n",
        "    \"\"\"Enhanced Transformer for HAR with dynamic confidence scaling\"\"\"\n",
        "    def __init__(self, input_size, d_model=128, nhead=8, num_layers=3, num_classes=6):\n",
        "        super(TransformerHAR_Enhanced, self).__init__()\n",
        "\n",
        "        self.input_size = input_size  # 561 for HAR\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # For HAR: reshape 561 features into sequences\n",
        "        self.seq_len = 33  # 561 / 17 = 33\n",
        "        self.feature_per_step = 17\n",
        "\n",
        "        # Make sure d_model is divisible by nhead\n",
        "        if d_model % nhead != 0:\n",
        "            d_model = nhead * (d_model // nhead)\n",
        "            self.d_model = d_model\n",
        "\n",
        "        # Input projection\n",
        "        self.input_projection = nn.Linear(self.feature_per_step, d_model)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len=self.seq_len + 10)\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(d_model // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Handle input size variations\n",
        "        if x.shape[1] > 561:\n",
        "            x = x[:, :561]\n",
        "        elif x.shape[1] < 561:\n",
        "            padding = torch.zeros(batch_size, 561 - x.shape[1], device=x.device)\n",
        "            x = torch.cat([x, padding], dim=1)\n",
        "\n",
        "        # Reshape to (batch_size, seq_len, feature_per_step)\n",
        "        x = x.view(batch_size, self.seq_len, self.feature_per_step)\n",
        "\n",
        "        # Project to d_model dimensions\n",
        "        x = self.input_projection(x)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Add positional encoding\n",
        "        x_transposed = x.transpose(0, 1)  # (seq_len, batch_size, d_model)\n",
        "        x_with_pos = self.pos_encoder(x_transposed)\n",
        "        x = x_with_pos.transpose(0, 1)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Transformer\n",
        "        transformer_out = self.transformer(x)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Global average pooling\n",
        "        pooled = torch.mean(transformer_out, dim=1)  # (batch_size, d_model)\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(pooled)\n",
        "\n",
        "        return logits\n",
        "\n",
        "class TACL_HAR(nn.Module):\n",
        "    \"\"\"TACL-Net model for HAR classification\"\"\"\n",
        "    def __init__(self, input_dim=561, n_classes=6, latent_dim=128):\n",
        "        super().__init__()\n",
        "        self.encoder = EnhancedMLPEncoder(input_dim, latent_dim)\n",
        "        self.activity_attention = ActivityAttention(latent_dim)\n",
        "\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Linear(latent_dim, latent_dim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Linear(latent_dim//2, n_classes)\n",
        "\n",
        "        self.confidence = nn.Sequential(\n",
        "            nn.Linear(latent_dim//2, 32),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.loss_fn = BalancedNoiseRobustLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        z_att = self.activity_attention(z)\n",
        "        z_bottleneck = self.bottleneck(z_att)\n",
        "\n",
        "        logits = self.classifier(z_bottleneck)\n",
        "        conf_scores = self.confidence(z_bottleneck).squeeze(-1) * 0.3 + 0.7  # Range [0.7, 1.0]\n",
        "\n",
        "        return {\n",
        "            'logits': logits,\n",
        "            'conf_scores': conf_scores\n",
        "        }\n",
        "\n",
        "\n",
        "# 4. ENHANCED TRAINING LOGGER\n",
        "class EnhancedTrainingLogger:\n",
        "    \"\"\"Enhanced training logger with comprehensive metrics for all models\"\"\"\n",
        "    def __init__(self, log_every=10):\n",
        "        self.log_every = log_every\n",
        "        self.epoch_logs = []\n",
        "\n",
        "    def log_epoch(self, epoch, loss, train_acc, val_acc, train_f1=None, val_f1=None,\n",
        "                  train_precision=None, val_precision=None, train_recall=None, val_recall=None, lr=None):\n",
        "        \"\"\"Log comprehensive epoch metrics\"\"\"\n",
        "        log_entry = {\n",
        "            'epoch': epoch,\n",
        "            'loss': loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_acc': val_acc,\n",
        "            'train_f1': train_f1,\n",
        "            'val_f1': val_f1,\n",
        "            'train_precision': train_precision,\n",
        "            'val_precision': val_precision,\n",
        "            'train_recall': train_recall,\n",
        "            'val_recall': val_recall,\n",
        "            'lr': lr\n",
        "        }\n",
        "        self.epoch_logs.append(log_entry)\n",
        "\n",
        "        if epoch == 1 or epoch % self.log_every == 0:\n",
        "            log_msg = f\"Epoch {epoch:3d}: Loss={loss:.4f}, TrainAcc={train_acc:.2f}%, ValAcc={val_acc:.2f}%\"\n",
        "            if train_f1 is not None:\n",
        "                log_msg += f\", TrainF1={train_f1:.3f}, ValF1={val_f1:.3f}\"\n",
        "            if train_precision is not None:\n",
        "                log_msg += f\", TrainP={train_precision:.3f}, ValP={val_precision:.3f}\"\n",
        "            if train_recall is not None:\n",
        "                log_msg += f\", TrainR={train_recall:.3f}, ValR={val_recall:.3f}\"\n",
        "            if lr is not None:\n",
        "                log_msg += f\", LR={lr:.6f}\"\n",
        "            print(log_msg)\n",
        "\n",
        "    def get_best_epoch(self):\n",
        "        \"\"\"Get the epoch with best validation accuracy\"\"\"\n",
        "        if not self.epoch_logs:\n",
        "            return None\n",
        "        best_epoch = max(self.epoch_logs, key=lambda x: x['val_acc'])\n",
        "        return best_epoch\n",
        "\n",
        "\n",
        "# 5. UTILITY FUNCTIONS\n",
        "def add_realistic_label_noise(y, subjects, noise_rate=0.1, n_classes=6):\n",
        "    \"\"\"Add realistic label noise based on activity confusion patterns\"\"\"\n",
        "    if noise_rate == 0:\n",
        "        return y.copy(), np.zeros(len(y), dtype=bool)\n",
        "\n",
        "    y_noisy = y.copy()\n",
        "    n_samples = len(y)\n",
        "    n_noisy = int(noise_rate * n_samples)\n",
        "\n",
        "    if n_noisy > 0:\n",
        "        # Activity confusion matrix (based on realistic confusions)\n",
        "        confusion_patterns = {\n",
        "            0: [1, 2],      # WALKING -> stairs activities\n",
        "            1: [0, 2],      # WALKING_UPSTAIRS -> walking activities\n",
        "            2: [0, 1],      # WALKING_DOWNSTAIRS -> walking activities\n",
        "            3: [4],         # SITTING -> STANDING\n",
        "            4: [3],         # STANDING -> SITTING\n",
        "            5: [3]          # LAYING -> SITTING (sensor orientation)\n",
        "        }\n",
        "\n",
        "        # Select samples for noise injection\n",
        "        noisy_indices = np.random.choice(n_samples, n_noisy, replace=False)\n",
        "\n",
        "        for idx in noisy_indices:\n",
        "            current_class = y[idx]\n",
        "            if current_class in confusion_patterns:\n",
        "                possible_confusions = confusion_patterns[current_class]\n",
        "                y_noisy[idx] = np.random.choice(possible_confusions)\n",
        "\n",
        "    noise_mask = np.zeros(n_samples, dtype=bool)\n",
        "    noise_mask[noisy_indices] = True\n",
        "\n",
        "    return y_noisy, noise_mask\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\"Calculate comprehensive metrics\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    return accuracy, f1, precision, recall\n",
        "\n",
        "\n",
        "# 6. TRAINING FUNCTIONS\n",
        "def train_tacl_one_epoch(model, data_loader, optimizer, epoch, device):\n",
        "    \"\"\"Training function for TACL-Net with SAM optimizer\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    for batch_X, batch_y in data_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        # Pseudo-labeling for high-confidence predictions\n",
        "        if epoch > 8:\n",
        "            with torch.no_grad():\n",
        "                outputs = model(batch_X)\n",
        "                high_conf_mask = (outputs['conf_scores'] > 0.9) & \\\n",
        "                               (F.softmax(outputs['logits'], dim=1).max(1)[0] > 0.85)\n",
        "                if high_conf_mask.any():\n",
        "                    pseudo_labels = outputs['logits'].argmax(-1)\n",
        "                    batch_y[high_conf_mask] = pseudo_labels[high_conf_mask]\n",
        "\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = model.loss_fn(outputs['logits'], batch_y, outputs['conf_scores'])\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            return loss\n",
        "\n",
        "        loss = closure()\n",
        "        optimizer.first_step(zero_grad=True)\n",
        "\n",
        "        closure()\n",
        "        optimizer.second_step(zero_grad=True)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate predictions for metrics\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch_X)\n",
        "            _, predicted = torch.max(outputs['logits'], 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    # Calculate comprehensive metrics\n",
        "    accuracy, f1, precision, recall = calculate_metrics(all_targets, all_preds)\n",
        "\n",
        "    return total_loss / len(data_loader), accuracy * 100, f1, precision, recall\n",
        "\n",
        "def train_baseline_one_epoch(model, data_loader, optimizer, device):\n",
        "    \"\"\"Training function for baseline models\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    for batch_X, batch_y in data_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch_X)\n",
        "        loss = F.cross_entropy(logits, batch_y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_targets.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    # Calculate comprehensive metrics\n",
        "    accuracy, f1, precision, recall = calculate_metrics(all_targets, all_preds)\n",
        "\n",
        "    return total_loss / len(data_loader), accuracy * 100, f1, precision, recall\n",
        "\n",
        "def evaluate_model(model, data_loader, device, model_type='baseline'):\n",
        "    \"\"\"Comprehensive evaluation for all models\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    all_conf = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            if model_type == 'tacl':\n",
        "                outputs = model(batch_X)\n",
        "                logits = outputs['logits']\n",
        "                conf_scores = outputs['conf_scores']\n",
        "            else:\n",
        "                logits = model(batch_X)\n",
        "                # Calculate confidence as max softmax probability\n",
        "                probabilities = torch.softmax(logits, dim=1)\n",
        "                conf_scores, _ = torch.max(probabilities, 1)\n",
        "\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(batch_y.cpu().numpy())\n",
        "            all_conf.extend(conf_scores.cpu().numpy())\n",
        "\n",
        "    # Calculate comprehensive metrics\n",
        "    accuracy, f1, precision, recall = calculate_metrics(all_targets, all_preds)\n",
        "    mean_confidence = np.mean(all_conf)\n",
        "\n",
        "    return accuracy * 100, f1, precision, recall, mean_confidence, all_preds, all_targets\n",
        "\n",
        "def train_model_enhanced(model, train_loader, val_loader, device, model_type='baseline',\n",
        "                        num_epochs=100, patience=15, verbose=True):\n",
        "    \"\"\"Enhanced training with comprehensive metrics logging\"\"\"\n",
        "\n",
        "    logger = EnhancedTrainingLogger(log_every=20)\n",
        "\n",
        "    # Setup optimizer based on model type\n",
        "    if model_type == 'tacl':\n",
        "        optimizer = SAM(model.parameters(), torch.optim.AdamW, rho=0.05, lr=1e-3, weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer.base_optimizer, T_max=40, eta_min=1e-6)\n",
        "    else:\n",
        "        if model_type == 'cnn' or model_type == 'lstm':\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "        else:  # transformer\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=7, factor=0.5)\n",
        "\n",
        "    model.to(device)\n",
        "    best_val_acc = 0\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        if model_type == 'tacl':\n",
        "            train_loss, train_acc, train_f1, train_precision, train_recall = train_tacl_one_epoch(\n",
        "                model, train_loader, optimizer, epoch + 1, device\n",
        "            )\n",
        "        else:\n",
        "            train_loss, train_acc, train_f1, train_precision, train_recall = train_baseline_one_epoch(\n",
        "                model, train_loader, optimizer, device\n",
        "            )\n",
        "\n",
        "        # Validation phase\n",
        "        val_acc, val_f1, val_precision, val_recall, val_conf, _, _ = evaluate_model(\n",
        "            model, val_loader, device, model_type\n",
        "        )\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        current_lr = optimizer.param_groups[0]['lr'] if model_type != 'tacl' else optimizer.base_optimizer.param_groups[0]['lr']\n",
        "\n",
        "        if model_type == 'tacl':\n",
        "            scheduler.step()\n",
        "        else:\n",
        "            scheduler.step(train_loss)\n",
        "\n",
        "        # Log comprehensive metrics\n",
        "        if verbose:\n",
        "            logger.log_epoch(\n",
        "                epoch + 1, train_loss, train_acc, val_acc,\n",
        "                train_f1, val_f1, train_precision, val_precision,\n",
        "                train_recall, val_recall, current_lr\n",
        "            )\n",
        "\n",
        "        # Early stopping\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            patience_counter = 0\n",
        "            best_model_state = model.state_dict().copy()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            if verbose:\n",
        "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
        "            break\n",
        "\n",
        "    # Load best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    best_epoch_info = logger.get_best_epoch()\n",
        "\n",
        "    return model, best_val_acc, {\n",
        "        'training_time': training_time,\n",
        "        'best_epoch': best_epoch_info,\n",
        "        'total_epochs': epoch + 1,\n",
        "        'logs': logger.epoch_logs\n",
        "    }\n",
        "\n",
        "def get_detailed_evaluation(model, test_loader, device, class_labels, model_type='baseline'):\n",
        "    \"\"\"Get detailed evaluation with classification report\"\"\"\n",
        "    test_acc, test_f1, test_precision, test_recall, test_conf, all_preds, all_targets = evaluate_model(\n",
        "        model, test_loader, device, model_type\n",
        "    )\n",
        "\n",
        "    report = classification_report(\n",
        "        all_targets, all_preds,\n",
        "        target_names=class_labels,\n",
        "        digits=4\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        'test_acc': test_acc,\n",
        "        'test_f1': test_f1,\n",
        "        'test_precision': test_precision,\n",
        "        'test_recall': test_recall,\n",
        "        'confidence': test_conf,\n",
        "        'report': report,\n",
        "        'predictions': all_preds,\n",
        "        'targets': all_targets\n",
        "    }\n",
        "\n",
        "\n",
        "# 7. MAIN EXPERIMENT FUNCTION\n",
        "def run_integrated_experiments(X_train, y_train, X_test, y_test, device,\n",
        "                              class_labels, noise_level=0.0, verbose=True):\n",
        "    \"\"\"Run experiments with all four models: CNN, LSTM, Transformer, TACL-Net\"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"INTEGRATED HAR EXPERIMENT - NOISE LEVEL: {noise_level}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "    # Add label noise if specified\n",
        "    if noise_level > 0:\n",
        "        subjects_dummy = np.ones(len(y_train), dtype=int)  # Create dummy subjects\n",
        "        y_train_noisy, noise_mask = add_realistic_label_noise(y_train, subjects_dummy, noise_level)\n",
        "        if verbose:\n",
        "            print(f\"Added noise to {noise_mask.sum()}/{len(y_train)} training samples\")\n",
        "    else:\n",
        "        y_train_noisy = y_train.copy()\n",
        "        noise_mask = np.zeros(len(y_train), dtype=bool)\n",
        "\n",
        "    # Prepare data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Split training data for validation\n",
        "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
        "        X_train_scaled, y_train_noisy, test_size=0.2, random_state=42, stratify=y_train_noisy\n",
        "    )\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = TensorDataset(torch.FloatTensor(X_train_split), torch.LongTensor(y_train_split))\n",
        "    val_dataset = TensorDataset(torch.FloatTensor(X_val_split), torch.LongTensor(y_val_split))\n",
        "    test_dataset = TensorDataset(torch.FloatTensor(X_test_scaled), torch.LongTensor(y_test))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    input_size = X_train.shape[1]\n",
        "    num_classes = len(np.unique(y_train))\n",
        "\n",
        "    results = {}\n",
        "    models = {}\n",
        "\n",
        "    # Model configurations\n",
        "    model_configs = [\n",
        "        ('1D-CNN', CNN1D_HAR_Enhanced(input_size, num_classes), 'cnn'),\n",
        "        ('Bi-LSTM', BiLSTM_HAR_Enhanced(input_size, num_classes=num_classes), 'lstm'),\n",
        "        ('Transformer', TransformerHAR_Enhanced(input_size, num_classes=num_classes), 'transformer'),\n",
        "        ('TACL-Net', TACL_HAR(input_dim=input_size, n_classes=num_classes, latent_dim=128), 'tacl')\n",
        "    ]\n",
        "\n",
        "    for model_name, model, model_type in model_configs:\n",
        "        if verbose:\n",
        "            print(f\"\\n{'-'*70}\")\n",
        "            print(f\"Training {model_name}...\")\n",
        "            print(f\"{'-'*70}\")\n",
        "\n",
        "        # Train model\n",
        "        trained_model, val_acc, training_info = train_model_enhanced(\n",
        "            model, train_loader, val_loader, device, model_type, verbose=verbose\n",
        "        )\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_results = get_detailed_evaluation(\n",
        "            trained_model, test_loader, device, class_labels, model_type\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        results[model_name] = {\n",
        "            'val_acc': val_acc,\n",
        "            'test_acc': test_results['test_acc'],\n",
        "            'test_f1': test_results['test_f1'],\n",
        "            'test_precision': test_results['test_precision'],\n",
        "            'test_recall': test_results['test_recall'],\n",
        "            'confidence': test_results['confidence'],\n",
        "            'report': test_results['report'],\n",
        "            'training_info': training_info,\n",
        "            'noise_level': noise_level\n",
        "        }\n",
        "        models[model_name] = trained_model\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\n{model_name} Results:\")\n",
        "            print(f\"  Validation Accuracy: {val_acc:.2f}%\")\n",
        "            print(f\"  Test Accuracy:      {test_results['test_acc']:.2f}%\")\n",
        "            print(f\"  Test F1-Score:      {test_results['test_f1']:.4f}\")\n",
        "            print(f\"  Test Precision:     {test_results['test_precision']:.4f}\")\n",
        "            print(f\"  Test Recall:        {test_results['test_recall']:.4f}\")\n",
        "            print(f\"  Mean Confidence:    {test_results['confidence']:.3f}\")\n",
        "            print(f\"  Training Time:      {training_info['training_time']:.1f}s\")\n",
        "            print(f\"  Total Epochs:       {training_info['total_epochs']}\")\n",
        "\n",
        "    return results, models\n",
        "\n",
        "def run_noise_robustness_integrated(X_train, y_train, X_test, y_test, device, class_labels, verbose=True):\n",
        "    \"\"\"Run noise robustness experiments with all four models\"\"\"\n",
        "\n",
        "    noise_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "    all_results = {}\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\"*80)\n",
        "        print(\"COMPREHENSIVE NOISE ROBUSTNESS EXPERIMENTS (ALL 4 MODELS)\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    for noise_level in noise_levels:\n",
        "        if verbose:\n",
        "            print(f\"\\n{'='*20} NOISE LEVEL: {noise_level:.1f} {'='*20}\")\n",
        "\n",
        "        results, models = run_integrated_experiments(\n",
        "            X_train, y_train, X_test, y_test, device,\n",
        "            class_labels, noise_level, verbose=verbose\n",
        "        )\n",
        "\n",
        "        all_results[noise_level] = results\n",
        "\n",
        "        # Print summary for this noise level\n",
        "        if verbose:\n",
        "            print(f\"\\nSUMMARY FOR NOISE LEVEL {noise_level:.1f}:\")\n",
        "            print(\"-\" * 60)\n",
        "            for model_name, metrics in results.items():\n",
        "                print(f\"{model_name:12}: Acc={metrics['test_acc']:6.2f}%, \"\n",
        "                      f\"F1={metrics['test_f1']:.3f}, P={metrics['test_precision']:.3f}, \"\n",
        "                      f\"R={metrics['test_recall']:.3f}, Conf={metrics['confidence']:.3f}\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def print_comprehensive_comparison(all_results, verbose=True):\n",
        "    \"\"\"Print comprehensive comparison of all four models\"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\"*120)\n",
        "        print(\"COMPREHENSIVE COMPARISON: ALL FOUR MODELS ACROSS NOISE LEVELS\")\n",
        "        print(\"=\"*120)\n",
        "\n",
        "    noise_levels = sorted(all_results.keys())\n",
        "    model_names = list(all_results[0.0].keys())\n",
        "\n",
        "    # Accuracy comparison\n",
        "    if verbose:\n",
        "        print(f\"\\nACCURACY COMPARISON:\")\n",
        "        print(\"-\" * 120)\n",
        "        print(f\"{'Model':<12} | {'Clean (0.0)':<12} | {'Noise 0.1':<12} | {'Noise 0.2':<12} | {'Noise 0.3':<12} | {'Avg Time(s)':<12} | {'Robustness':<10}\")\n",
        "        print(\"-\" * 120)\n",
        "\n",
        "    for model_name in model_names:\n",
        "        if verbose:\n",
        "            row = f\"{model_name:<12} |\"\n",
        "            accuracies = []\n",
        "            for noise_level in noise_levels:\n",
        "                acc = all_results[noise_level][model_name]['test_acc']\n",
        "                accuracies.append(acc)\n",
        "                row += f\" {acc:>10.2f}% |\"\n",
        "\n",
        "            # Add average training time\n",
        "            avg_time = np.mean([all_results[noise][model_name]['training_info']['training_time']\n",
        "                              for noise in noise_levels])\n",
        "            row += f\" {avg_time:>10.1f}s |\"\n",
        "\n",
        "            # Add robustness score (clean vs noisy performance retention)\n",
        "            robustness = (accuracies[-1] / accuracies[0]) * 100\n",
        "            row += f\" {robustness:>8.1f}%\"\n",
        "            print(row)\n",
        "\n",
        "    # F1-Score comparison\n",
        "    if verbose:\n",
        "        print(f\"\\nF1-SCORE COMPARISON:\")\n",
        "        print(\"-\" * 120)\n",
        "        print(f\"{'Model':<12} | {'Clean (0.0)':<12} | {'Noise 0.1':<12} | {'Noise 0.2':<12} | {'Noise 0.3':<12} | {'F1 Drop':<12}\")\n",
        "        print(\"-\" * 120)\n",
        "\n",
        "    for model_name in model_names:\n",
        "        if verbose:\n",
        "            row = f\"{model_name:<12} |\"\n",
        "            f1_scores = []\n",
        "            for noise_level in noise_levels:\n",
        "                f1 = all_results[noise_level][model_name]['test_f1']\n",
        "                f1_scores.append(f1)\n",
        "                row += f\" {f1:>10.4f} |\"\n",
        "\n",
        "            # Add F1 drop\n",
        "            f1_drop = f1_scores[0] - f1_scores[-1]\n",
        "            row += f\" {f1_drop:>10.4f}\"\n",
        "            print(row)\n",
        "\n",
        "    # Model rankings\n",
        "    if verbose:\n",
        "        print(f\"\\nMODEL RANKINGS:\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # Rank by clean performance\n",
        "        clean_ranking = sorted(model_names, key=lambda x: all_results[0.0][x]['test_acc'], reverse=True)\n",
        "        print(f\"Clean Performance:  {' > '.join(clean_ranking)}\")\n",
        "\n",
        "        # Rank by robustness\n",
        "        robustness_scores = {}\n",
        "        for model_name in model_names:\n",
        "            clean_acc = all_results[0.0][model_name]['test_acc']\n",
        "            noisy_acc = all_results[0.3][model_name]['test_acc']\n",
        "            robustness_scores[model_name] = (noisy_acc / clean_acc) * 100\n",
        "\n",
        "        robustness_ranking = sorted(model_names, key=lambda x: robustness_scores[x], reverse=True)\n",
        "        print(f\"Noise Robustness:   {' > '.join(robustness_ranking)}\")\n",
        "\n",
        "        # Rank by training efficiency\n",
        "        efficiency_scores = {}\n",
        "        for model_name in model_names:\n",
        "            avg_time = np.mean([all_results[noise][model_name]['training_info']['training_time']\n",
        "                              for noise in noise_levels])\n",
        "            efficiency_scores[model_name] = avg_time\n",
        "\n",
        "        efficiency_ranking = sorted(model_names, key=lambda x: efficiency_scores[x])\n",
        "        print(f\"Training Efficiency: {' > '.join(efficiency_ranking)} (fastest to slowest)\")\n",
        "\n",
        "def generate_model_recommendations(all_results, verbose=True):\n",
        "    \"\"\"Generate comprehensive model recommendations\"\"\"\n",
        "    if not verbose:\n",
        "        return\n",
        "\n",
        "    # NOTE: This function now only computes metrics without printing recommendations\n",
        "    noise_levels = sorted(all_results.keys())\n",
        "    model_names = list(all_results[0.0].keys())\n",
        "\n",
        "    # Calculate comprehensive metrics\n",
        "    model_metrics = {}\n",
        "    for model_name in model_names:\n",
        "        clean_acc = all_results[0.0][model_name]['test_acc']\n",
        "        clean_f1 = all_results[0.0][model_name]['test_f1']\n",
        "        noisy_acc = all_results[0.3][model_name]['test_acc']\n",
        "        noisy_f1 = all_results[0.3][model_name]['test_f1']\n",
        "\n",
        "        avg_time = np.mean([all_results[noise][model_name]['training_info']['training_time']\n",
        "                          for noise in noise_levels])\n",
        "        avg_epochs = np.mean([all_results[noise][model_name]['training_info']['total_epochs']\n",
        "                            for noise in noise_levels])\n",
        "\n",
        "        robustness_acc = (noisy_acc / clean_acc) * 100\n",
        "        robustness_f1 = (noisy_f1 / clean_f1) * 100\n",
        "\n",
        "        clean_conf = all_results[0.0][model_name]['confidence']\n",
        "        noisy_conf = all_results[0.3][model_name]['confidence']\n",
        "\n",
        "        model_metrics[model_name] = {\n",
        "            'clean_acc': clean_acc,\n",
        "            'clean_f1': clean_f1,\n",
        "            'noisy_acc': noisy_acc,\n",
        "            'noisy_f1': noisy_f1,\n",
        "            'robustness_acc': robustness_acc,\n",
        "            'robustness_f1': robustness_f1,\n",
        "            'avg_time': avg_time,\n",
        "            'avg_epochs': avg_epochs,\n",
        "            'clean_conf': clean_conf,\n",
        "            'noisy_conf': noisy_conf\n",
        "        }\n",
        "\n",
        "def create_comprehensive_plots(all_results, save_prefix=\"har_four_models\", verbose=True):\n",
        "    \"\"\"Create comprehensive visualization plots for all four models\"\"\"\n",
        "    try:\n",
        "        noise_levels = sorted(all_results.keys())\n",
        "        model_names = list(all_results[0.0].keys())\n",
        "\n",
        "        # Set up the plotting style\n",
        "        plt.style.use('default')\n",
        "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # Blue, Orange, Green, Red\n",
        "\n",
        "        # Create comprehensive figure with 11 subplots (removed subplot 12)\n",
        "        fig = plt.figure(figsize=(24, 18))\n",
        "\n",
        "        # 1. Accuracy vs Noise Level\n",
        "        plt.subplot(3, 4, 1)\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            accuracies = [all_results[noise][model_name]['test_acc'] for noise in noise_levels]\n",
        "            plt.plot(noise_levels, accuracies, marker='o', label=model_name,\n",
        "                    linewidth=2.5, markersize=8, color=colors[i])\n",
        "\n",
        "        plt.xlabel('Noise Level', fontsize=12)\n",
        "        plt.ylabel('Test Accuracy (%)', fontsize=12)\n",
        "        plt.title('Test Accuracy vs Label Noise', fontsize=14, fontweight='bold')\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 2. F1-Score vs Noise Level\n",
        "        plt.subplot(3, 4, 2)\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            f1_scores = [all_results[noise][model_name]['test_f1'] for noise in noise_levels]\n",
        "            plt.plot(noise_levels, f1_scores, marker='s', label=model_name,\n",
        "                    linewidth=2.5, markersize=8, color=colors[i])\n",
        "\n",
        "        plt.xlabel('Noise Level', fontsize=12)\n",
        "        plt.ylabel('Test F1-Score', fontsize=12)\n",
        "        plt.title('F1-Score vs Label Noise', fontsize=14, fontweight='bold')\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. Precision vs Noise Level\n",
        "        plt.subplot(3, 4, 3)\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            precisions = [all_results[noise][model_name]['test_precision'] for noise in noise_levels]\n",
        "            plt.plot(noise_levels, precisions, marker='^', label=model_name,\n",
        "                    linewidth=2.5, markersize=8, color=colors[i])\n",
        "\n",
        "        plt.xlabel('Noise Level', fontsize=12)\n",
        "        plt.ylabel('Test Precision', fontsize=12)\n",
        "        plt.title('Precision vs Label Noise', fontsize=14, fontweight='bold')\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. Recall vs Noise Level\n",
        "        plt.subplot(3, 4, 4)\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            recalls = [all_results[noise][model_name]['test_recall'] for noise in noise_levels]\n",
        "            plt.plot(noise_levels, recalls, marker='v', label=model_name,\n",
        "                    linewidth=2.5, markersize=8, color=colors[i])\n",
        "\n",
        "        plt.xlabel('Noise Level', fontsize=12)\n",
        "        plt.ylabel('Test Recall', fontsize=12)\n",
        "        plt.title('Recall vs Label Noise', fontsize=14, fontweight='bold')\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 5. Confidence vs Noise Level\n",
        "        plt.subplot(3, 4, 5)\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            confidences = [all_results[noise][model_name]['confidence'] for noise in noise_levels]\n",
        "            plt.plot(noise_levels, confidences, marker='d', label=model_name,\n",
        "                    linewidth=2.5, markersize=8, color=colors[i])\n",
        "\n",
        "        plt.xlabel('Noise Level', fontsize=12)\n",
        "        plt.ylabel('Mean Confidence', fontsize=12)\n",
        "        plt.title('Model Confidence vs Label Noise', fontsize=14, fontweight='bold')\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 6. Training Time Comparison\n",
        "        plt.subplot(3, 4, 6)\n",
        "        avg_times = []\n",
        "        for model_name in model_names:\n",
        "            times = [all_results[noise][model_name]['training_info']['training_time']\n",
        "                    for noise in noise_levels]\n",
        "            avg_time = np.mean(times)\n",
        "            avg_times.append(avg_time)\n",
        "\n",
        "        bars = plt.bar(model_names, avg_times, alpha=0.7, color=colors)\n",
        "        plt.ylabel('Average Training Time (s)', fontsize=12)\n",
        "        plt.title('Average Training Time Comparison', fontsize=14, fontweight='bold')\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        for bar, time_val in zip(bars, avg_times):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(avg_times)*0.01,\n",
        "                    f'{time_val:.1f}s', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        # 7. Clean Dataset Performance\n",
        "        plt.subplot(3, 4, 7)\n",
        "        clean_accs = [all_results[0.0][model]['test_acc'] for model in model_names]\n",
        "        clean_f1s = [all_results[0.0][model]['test_f1'] for model in model_names]\n",
        "\n",
        "        x_pos = np.arange(len(model_names))\n",
        "        width = 0.35\n",
        "\n",
        "        bars1 = plt.bar(x_pos - width/2, clean_accs, width, label='Accuracy (%)', alpha=0.7)\n",
        "        bars2 = plt.bar(x_pos + width/2, [f1*100 for f1 in clean_f1s], width, label='F1-Score (x100)', alpha=0.7)\n",
        "\n",
        "        plt.xlabel('Model', fontsize=12)\n",
        "        plt.ylabel('Performance', fontsize=12)\n",
        "        plt.title('Clean Dataset Performance', fontsize=14, fontweight='bold')\n",
        "        plt.xticks(x_pos, model_names, rotation=45)\n",
        "        plt.legend()\n",
        "\n",
        "        # 8. Robustness Scores\n",
        "        plt.subplot(3, 4, 8)\n",
        "        robustness_scores = []\n",
        "        for model_name in model_names:\n",
        "            clean_acc = all_results[0.0][model_name]['test_acc']\n",
        "            noisy_acc = all_results[0.3][model_name]['test_acc']\n",
        "            robustness = (noisy_acc / clean_acc) * 100\n",
        "            robustness_scores.append(robustness)\n",
        "\n",
        "        bars = plt.bar(model_names, robustness_scores, alpha=0.7, color=colors)\n",
        "        plt.ylabel('Robustness Score (%)', fontsize=12)\n",
        "        plt.title('Robustness to High Noise (30%)', fontsize=14, fontweight='bold')\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        for bar, score in zip(bars, robustness_scores):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "                    f'{score:.1f}%', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        # 9. Accuracy Heatmap\n",
        "        plt.subplot(3, 4, 9)\n",
        "        accuracy_matrix = []\n",
        "        for model_name in model_names:\n",
        "            model_accuracies = [all_results[noise][model_name]['test_acc'] for noise in noise_levels]\n",
        "            accuracy_matrix.append(model_accuracies)\n",
        "\n",
        "        sns.heatmap(accuracy_matrix, xticklabels=[f'{n:.1f}' for n in noise_levels],\n",
        "                   yticklabels=model_names, annot=True, fmt='.1f', cmap='RdYlBu_r', cbar_kws={'label': 'Accuracy (%)'})\n",
        "        plt.title('Accuracy Heatmap', fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Noise Level', fontsize=12)\n",
        "\n",
        "        # 10. F1-Score Heatmap\n",
        "        plt.subplot(3, 4, 10)\n",
        "        f1_matrix = []\n",
        "        for model_name in model_names:\n",
        "            model_f1s = [all_results[noise][model_name]['test_f1'] for noise in noise_levels]\n",
        "            f1_matrix.append(model_f1s)\n",
        "\n",
        "        sns.heatmap(f1_matrix, xticklabels=[f'{n:.1f}' for n in noise_levels],\n",
        "                   yticklabels=model_names, annot=True, fmt='.3f', cmap='RdYlBu_r', cbar_kws={'label': 'F1-Score'})\n",
        "        plt.title('F1-Score Heatmap', fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Noise Level', fontsize=12)\n",
        "\n",
        "        # 11. Epochs to Convergence\n",
        "        plt.subplot(3, 4, 11)\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            epochs = [all_results[noise][model_name]['training_info']['total_epochs']\n",
        "                     for noise in noise_levels]\n",
        "            plt.plot(noise_levels, epochs, marker='o', label=model_name,\n",
        "                    linewidth=2.5, markersize=8, color=colors[i])\n",
        "\n",
        "        plt.xlabel('Noise Level', fontsize=12)\n",
        "        plt.ylabel('Epochs to Convergence', fontsize=12)\n",
        "        plt.title('Training Convergence', fontsize=14, fontweight='bold')\n",
        "        plt.legend(fontsize=10)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout(pad=3.0)\n",
        "\n",
        "        # Save the plot\n",
        "        if save_prefix:\n",
        "            save_path = f\"{save_prefix}_comprehensive_analysis.png\"\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            if verbose:\n",
        "                print(f\"Comprehensive plot saved to: {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # Create additional training curves plot\n",
        "        create_training_curves_plot(all_results, f\"{save_prefix}_training_curves.png\", verbose)\n",
        "\n",
        "    except ImportError:\n",
        "        if verbose:\n",
        "            print(\"Matplotlib/Seaborn not available. Skipping comprehensive plots.\")\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"Error creating comprehensive plots: {e}\")\n",
        "\n",
        "def create_training_curves_plot(all_results, save_path=None, verbose=True):\n",
        "    \"\"\"Create detailed training curves for each model and noise level\"\"\"\n",
        "    try:\n",
        "        noise_levels = sorted(all_results.keys())\n",
        "        model_names = list(all_results[0.0].keys())\n",
        "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "        fig, axes = plt.subplots(len(model_names), len(noise_levels),\n",
        "                                figsize=(20, 16), sharey=True)\n",
        "\n",
        "        if len(model_names) == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "\n",
        "        for i, model_name in enumerate(model_names):\n",
        "            for j, noise_level in enumerate(noise_levels):\n",
        "                ax = axes[i, j]\n",
        "\n",
        "                training_logs = all_results[noise_level][model_name]['training_info']['logs']\n",
        "\n",
        "                epochs = [log['epoch'] for log in training_logs]\n",
        "                train_accs = [log['train_acc'] for log in training_logs]\n",
        "                val_accs = [log['val_acc'] for log in training_logs]\n",
        "                losses = [log['loss'] for log in training_logs]\n",
        "                train_f1s = [log['train_f1'] if log['train_f1'] else 0 for log in training_logs]\n",
        "                val_f1s = [log['val_f1'] if log['val_f1'] else 0 for log in training_logs]\n",
        "\n",
        "                # Plot accuracy and F1 curves\n",
        "                ax2 = ax.twinx()\n",
        "                line1 = ax.plot(epochs, train_accs, 'b-', label='Train Acc', linewidth=2, alpha=0.7)\n",
        "                line2 = ax.plot(epochs, val_accs, 'g-', label='Val Acc', linewidth=2)\n",
        "                line3 = ax.plot(epochs, [f1*100 for f1 in train_f1s], 'b--', label='Train F1 (x100)', linewidth=1.5, alpha=0.7)\n",
        "                line4 = ax.plot(epochs, [f1*100 for f1 in val_f1s], 'g--', label='Val F1 (x100)', linewidth=1.5)\n",
        "                line5 = ax2.plot(epochs, losses, 'r:', label='Loss', linewidth=2, alpha=0.8)\n",
        "\n",
        "                ax.set_xlabel('Epoch', fontsize=10)\n",
        "                ax.set_ylabel('Accuracy (%) / F1 (x100)', color='black', fontsize=10)\n",
        "                ax2.set_ylabel('Loss', color='red', fontsize=10)\n",
        "                ax.set_title(f'{model_name} - Noise {noise_level:.1f}', fontsize=11)\n",
        "\n",
        "                # Mark best epoch\n",
        "                best_epoch_info = all_results[noise_level][model_name]['training_info']['best_epoch']\n",
        "                if best_epoch_info:\n",
        "                    best_epoch = best_epoch_info['epoch']\n",
        "                    best_val_acc = best_epoch_info['val_acc']\n",
        "                    ax.axvline(x=best_epoch, color='orange', linestyle=':', alpha=0.7, linewidth=2)\n",
        "                    ax.plot(best_epoch, best_val_acc, 'o', color='orange', markersize=8)\n",
        "\n",
        "                ax.grid(True, alpha=0.3)\n",
        "\n",
        "                # Combine legends\n",
        "                lines = line1 + line2 + line3 + line4 + line5\n",
        "                labels = [l.get_label() for l in lines]\n",
        "                if i == 0 and j == 0:  # Only show legend on first subplot\n",
        "                    ax.legend(lines, labels, loc='lower right', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            if verbose:\n",
        "                print(f\"Training curves plot saved to: {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"Error creating training curves plot: {e}\")\n",
        "\n",
        "def print_classification_reports(all_results, noise_level=0.0, verbose=True):\n",
        "    \"\"\"Print detailed classification reports for all models\"\"\"\n",
        "    if not verbose:\n",
        "        return\n",
        "\n",
        "    print(f\"\\nDETAILED CLASSIFICATION REPORTS (Noise Level: {noise_level})\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    results = all_results[noise_level]\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"\\n{model_name} Classification Report:\")\n",
        "        print(\"-\" * 50)\n",
        "        print(metrics['report'])\n",
        "\n",
        "def save_comprehensive_results(all_results, models=None, save_dir=\"./har_four_models_results\", verbose=True):\n",
        "    \"\"\"Save comprehensive results including all metrics and models\"\"\"\n",
        "    try:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        # Save all results\n",
        "        with open(os.path.join(save_dir, \"comprehensive_results.pkl\"), \"wb\") as f:\n",
        "            pickle.dump(all_results, f)\n",
        "\n",
        "        # Save summary as JSON\n",
        "        summary_data = {}\n",
        "        for noise_level, noise_results in all_results.items():\n",
        "            summary_data[f\"noise_{noise_level}\"] = {}\n",
        "            for model_name, metrics in noise_results.items():\n",
        "                summary_data[f\"noise_{noise_level}\"][model_name] = {\n",
        "                    'test_accuracy': metrics['test_acc'],\n",
        "                    'test_f1': metrics['test_f1'],\n",
        "                    'test_precision': metrics['test_precision'],\n",
        "                    'test_recall': metrics['test_recall'],\n",
        "                    'validation_accuracy': metrics['val_acc'],\n",
        "                    'confidence': metrics['confidence'],\n",
        "                    'training_time': metrics['training_info']['training_time'],\n",
        "                    'total_epochs': metrics['training_info']['total_epochs'],\n",
        "                    'best_epoch': metrics['training_info']['best_epoch']['epoch'] if metrics['training_info']['best_epoch'] else None\n",
        "                }\n",
        "\n",
        "        with open(os.path.join(save_dir, \"results_summary.json\"), \"w\") as f:\n",
        "            json.dump(summary_data, f, indent=2)\n",
        "\n",
        "        # Save models from clean dataset\n",
        "        if models and 0.0 in all_results:\n",
        "            for model_name, model in models.items():\n",
        "                model_path = os.path.join(save_dir, f\"{model_name.lower().replace('-', '_')}_model.pth\")\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                if verbose:\n",
        "                    print(f\"Saved {model_name} model to: {model_path}\")\n",
        "\n",
        "        # Save detailed training logs as CSV\n",
        "        for noise_level, noise_results in all_results.items():\n",
        "            for model_name, metrics in noise_results.items():\n",
        "                training_logs = metrics['training_info']['logs']\n",
        "                df_logs = pd.DataFrame(training_logs)\n",
        "                log_path = os.path.join(save_dir, f\"training_logs_{model_name.lower().replace('-', '_')}_noise_{noise_level}.csv\")\n",
        "                df_logs.to_csv(log_path, index=False)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"All comprehensive results saved to: {save_dir}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"Error saving results: {e}\")\n",
        "\n",
        "def create_synthetic_har_data():\n",
        "    \"\"\"Create synthetic HAR data for testing when real dataset is not available\"\"\"\n",
        "    print(\"Creating synthetic HAR data for testing...\")\n",
        "\n",
        "    # Generate synthetic features (561 features like real HAR)\n",
        "    np.random.seed(42)\n",
        "    n_train, n_test = 7352, 2947\n",
        "    n_features = 561\n",
        "    n_classes = 6\n",
        "\n",
        "    # Create synthetic training data\n",
        "    X_train = np.random.randn(n_train, n_features)\n",
        "    y_train = np.random.randint(0, n_classes, n_train)\n",
        "\n",
        "    # Create synthetic test data\n",
        "    X_test = np.random.randn(n_test, n_features)\n",
        "    y_test = np.random.randint(0, n_classes, n_test)\n",
        "\n",
        "    # Add some structure to make it more realistic\n",
        "    for class_idx in range(n_classes):\n",
        "        train_mask = y_train == class_idx\n",
        "        test_mask = y_test == class_idx\n",
        "\n",
        "        # Add class-specific bias to certain features\n",
        "        feature_bias = np.random.randn(n_features) * 0.5\n",
        "        X_train[train_mask] += feature_bias\n",
        "        X_test[test_mask] += feature_bias\n",
        "\n",
        "    print(f\"Generated synthetic data:\")\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"X_test shape: {X_test.shape}\")\n",
        "    print(f\"Classes: {np.unique(y_train)}\")\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "# 8. MAIN EXECUTION FUNCTIONS\n",
        "def main_integrated_experiment():\n",
        "    \"\"\"Main function for comprehensive four-model experiment\"\"\"\n",
        "\n",
        "    print(\"HAR Integrated Baseline Models + TACL-Net Experiment\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "    # Initialize data loader\n",
        "    data_loader = UCIHARDataLoader(data_dir=\"/content\", download=True)\n",
        "\n",
        "    # Load data\n",
        "    try:\n",
        "        X_train, y_train, X_test, y_test, subject_train, subject_test = data_loader.load_data()\n",
        "        print(\"Successfully loaded UCI HAR dataset\")\n",
        "    except:\n",
        "        print(\"Failed to load UCI HAR dataset. Using synthetic data for demonstration.\")\n",
        "        X_train, y_train, X_test, y_test = create_synthetic_har_data()\n",
        "\n",
        "    print(f\"\\nHAR Dataset Summary:\")\n",
        "    print(f\"Training samples: {X_train.shape[0]}\")\n",
        "    print(f\"Test samples: {X_test.shape[0]}\")\n",
        "    print(f\"Features: {X_train.shape[1]}\")\n",
        "    print(f\"Classes: {len(np.unique(y_train))}\")\n",
        "\n",
        "    class_labels = data_loader.activities\n",
        "\n",
        "    print(\"\\nExperiment Options:\")\n",
        "    print(\"1. Clean data only (all 4 models)\")\n",
        "    print(\"2. Noise robustness analysis (all noise levels)\")\n",
        "    print(\"3. Both clean and noise analysis\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"Choose experiment type (1, 2, or 3, default=3): \").strip()\n",
        "    except:\n",
        "        choice = '3'  # Default for non-interactive environments\n",
        "\n",
        "    if choice == '1':\n",
        "        # Clean data only\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CLEAN HAR DATA EXPERIMENT (ALL 4 MODELS)\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        results, models = run_integrated_experiments(\n",
        "            X_train, y_train, X_test, y_test, device, class_labels,\n",
        "            noise_level=0.0, verbose=True\n",
        "        )\n",
        "\n",
        "        print_classification_reports({0.0: results}, 0.0)\n",
        "\n",
        "        return {0.0: results}, models\n",
        "\n",
        "    elif choice == '2':\n",
        "        # Noise robustness only\n",
        "        all_results = run_noise_robustness_integrated(\n",
        "            X_train, y_train, X_test, y_test, device, class_labels\n",
        "        )\n",
        "\n",
        "        print_comprehensive_comparison(all_results)\n",
        "        generate_model_recommendations(all_results)\n",
        "        create_comprehensive_plots(all_results)\n",
        "\n",
        "        return all_results, None\n",
        "\n",
        "    else:\n",
        "        # Both clean and noise analysis\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPREHENSIVE FOUR-MODEL HAR ANALYSIS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Run noise robustness analysis\n",
        "        all_results = run_noise_robustness_integrated(\n",
        "            X_train, y_train, X_test, y_test, device, class_labels\n",
        "        )\n",
        "\n",
        "        # Print classification reports for clean data\n",
        "        print_classification_reports(all_results, 0.0)\n",
        "\n",
        "        # Comprehensive analysis\n",
        "        print_comprehensive_comparison(all_results)\n",
        "        generate_model_recommendations(all_results)\n",
        "\n",
        "        # Create visualizations\n",
        "        try:\n",
        "            plot_choice = input(\"\\nGenerate comprehensive plots? (y/n, default=y): \").lower()\n",
        "        except:\n",
        "            plot_choice = 'y'\n",
        "\n",
        "        if plot_choice != 'n':\n",
        "            create_comprehensive_plots(all_results)\n",
        "\n",
        "        # Save results\n",
        "        try:\n",
        "            save_choice = input(\"Save comprehensive results and models? (y/n, default=y): \").lower()\n",
        "        except:\n",
        "            save_choice = 'y'\n",
        "\n",
        "        if save_choice != 'n':\n",
        "            clean_models = None\n",
        "            if 0.0 in all_results:\n",
        "                # Re-run clean experiment to get models\n",
        "                _, clean_models = run_integrated_experiments(\n",
        "                    X_train, y_train, X_test, y_test, device, class_labels,\n",
        "                    noise_level=0.0, verbose=False\n",
        "                )\n",
        "            save_comprehensive_results(all_results, clean_models)\n",
        "\n",
        "        return all_results, clean_models\n",
        "\n",
        "def quick_demo():\n",
        "    \"\"\"Quick demonstration of the integrated framework\"\"\"\n",
        "    print(\"HAR Integrated Models (CNN + LSTM + Transformer + TACL-Net) - Quick Demo\")\n",
        "    print(\"=\"*75)\n",
        "\n",
        "    # Create synthetic demo data\n",
        "    X_train, y_train, X_test, y_test = create_synthetic_har_data()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    class_labels = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING']\n",
        "\n",
        "    print(\"\\nRunning quick integrated experiment...\")\n",
        "\n",
        "    # Run a single experiment with clean data\n",
        "    results, models = run_integrated_experiments(\n",
        "        X_train, y_train, X_test, y_test, device, class_labels,\n",
        "        noise_level=0.0, verbose=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nQuick Demo Results Summary:\")\n",
        "    print(\"-\" * 50)\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"{model_name:12}: Acc={metrics['test_acc']:6.2f}%, \"\n",
        "              f\"F1={metrics['test_f1']:.4f}, Time={metrics['training_info']['training_time']:5.1f}s\")\n",
        "\n",
        "    print(\"\\nThis integrated framework provides:\")\n",
        "    print(\" All 4 models: 1D-CNN, Bi-LSTM, Transformer, TACL-Net\")\n",
        "    print(\" Comprehensive metrics: Accuracy, F1, Precision, Recall, Confidence\")\n",
        "    print(\" Enhanced logging with epoch-by-epoch tracking\")\n",
        "    print(\" Noise robustness analysis across multiple noise levels\")\n",
        "    print(\" Detailed visualizations and comparison plots\")\n",
        "    print(\" Complete result saving and model persistence\")\n",
        "    print(\" Realistic label noise patterns for HAR activities\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"HAR Integrated Baseline Models + TACL-Net\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"1. Run full integrated experiment\")\n",
        "    print(\"2. Show quick demo\")\n",
        "    print(\"3. Run with synthetic data only\")\n",
        "\n",
        "    try:\n",
        "        choice = input(\"Choose option (1, 2, or 3, default=1): \").strip()\n",
        "\n",
        "        if choice == '2':\n",
        "            quick_demo()\n",
        "        elif choice == '3':\n",
        "            # Run with synthetic data\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"RUNNING WITH SYNTHETIC HAR DATA\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            X_train, y_train, X_test, y_test = create_synthetic_har_data()\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            class_labels = ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS',\n",
        "                          'SITTING', 'STANDING', 'LAYING']\n",
        "\n",
        "            # Run noise robustness analysis\n",
        "            all_results = run_noise_robustness_integrated(\n",
        "                X_train, y_train, X_test, y_test, device, class_labels\n",
        "            )\n",
        "\n",
        "            print_comprehensive_comparison(all_results)\n",
        "            generate_model_recommendations(all_results)\n",
        "            create_comprehensive_plots(all_results)\n",
        "\n",
        "        else:\n",
        "            results, models = main_integrated_experiment()\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nExperiment interrupted by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during execution: {e}\")\n",
        "        # Fallback to synthetic data demo\n",
        "        print(\"\\nFalling back to synthetic data demo...\")\n",
        "        quick_demo()"
      ],
      "metadata": {
        "id": "1u1aa4RJ8oYX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}